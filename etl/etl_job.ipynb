{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, TimestampType, ShortType, DateType\n",
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/processed_btc_prices_ohlcvvw_2014-12-01_to_2018-11-11.csv\", nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'Open', 'High', 'Low', 'Close', 'Volume_(BTC)',\n",
       "       'Volume_(Currency)', 'Weighted_Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test_data/test_btc_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Initialized \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def initialize_spark():\n",
    "\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"Simple etl job\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    print(\"Spark Initialized\", \"\\n\")\n",
    "\n",
    "    return spark\n",
    "\n",
    "spark = initialize_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_without_schema(spark):\n",
    "\n",
    "    df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/processed_btc_prices_ohlcvvw_2014-12-01_to_2018-11-11.csv\")\n",
    "    return df\n",
    "\n",
    "df = load_df_without_schema(spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+---+-----+------------+-----------------+--------------+\n",
      "|_c0|date|Open|High|Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|\n",
      "+---+----+----+----+---+-----+------------+-----------------+--------------+\n",
      "|  0|   0|   0|   0|  0|    0|           0|                0|             0|\n",
      "+---+----+----+----+---+-----+------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_HEADERS = [\n",
    "    \"date\",\n",
    "    \"Open\",\n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Close\",\n",
    "    \"Volume_(BTC)\",\n",
    "    \"Volume_(Currency)\",\n",
    "    \"Weighted_Price\"]\n",
    "\n",
    "\n",
    "def test_column_headers():\n",
    "    assert df.schema.names == CORRECT_HEADERS, \"Column headers error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing(df, sort=True):\n",
    "    if len(df.select([count(when(isnan(c), c)).alias(c) for c in df.columns])) == 0:\n",
    "        print(\"No missing values\")\n",
    "        return None\n",
    "    if sort:\n",
    "        return df.rename(index={0: 'count'}).T.sort_values(\"count\",ascending=False)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_udacity_ai",
   "language": "python",
   "name": "py36_udacity_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
